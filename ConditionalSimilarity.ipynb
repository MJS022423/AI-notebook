{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "243e0487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import numpy as np\n",
    "import pathlib as path\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import torch.nn.functional as f\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torch.optim import Adam \n",
    "from torch.nn import TripletMarginLoss\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from time import time\n",
    "from torch.nn.functional import pairwise_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa0f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Earlystopper:\n",
    "  def __init__(self, min_delta = 0.0, patience = 1):\n",
    "    \n",
    "    self.min_delta = min_delta\n",
    "    self.patience = patience\n",
    "    self.best_validation = None\n",
    "    self.best_model_state = None\n",
    "    self.counter = 0\n",
    "    \n",
    "  def earlystop(self, validation_loss, model):\n",
    "    \n",
    "    if self.best_validation is None:\n",
    "      self.best_validation = validation_loss\n",
    "      self.best_model_state = copy.deepcopy(model.state_dict())\n",
    "      \n",
    "    elif validation_loss <= self.best_validation - self.min_delta:\n",
    "      \n",
    "      self.best_validation = validation_loss\n",
    "      self.best_model_state = copy.deepcopy(model.state_dict())\n",
    "      self.counter = 0\n",
    "    \n",
    "    else:\n",
    "      self.counter += 1\n",
    "      \n",
    "      print(f\"Earlystop: {self.counter}/{self.patience}\")\n",
    "      if self.counter >= self.patience:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "       \n",
    "  def restore_best_weight(self, model):\n",
    "    if self.best_model_state is not None:\n",
    "      model.load_state_dict(self.best_model_state)\n",
    "      print(\"Restored Best Weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a2f189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(anchor, positive, negative, margin=0.2):\n",
    "   \n",
    "    d_ap = torch.norm(anchor - positive, p=2, dim=1)\n",
    "    d_an = torch.norm(anchor - negative, p=2, dim=1)\n",
    "    \n",
    "    correct = (d_ap + margin < d_an).float()\n",
    "    accuracy = correct.mean().item()\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30073913",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseDataset(Dataset):\n",
    "  def __init__(self, image_dir=None, transform = None):\n",
    "    \n",
    "    self.image_dir = image_dir\n",
    "    self.transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale=(0.5, 1.0), ratio=(0.9, 1.1)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(13),\n",
    "        transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.02),\n",
    "        transforms.RandomAffine(degrees=20, translate=(0.05, 0.05)),\n",
    "        transforms.RandomGrayscale(p=0.05),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "      ])\n",
    "    \n",
    "    self.image = self.prepare_triplet_data(self.image_dir)\n",
    "  \n",
    "  @classmethod\n",
    "  def prepare_triplet_data(cls, image_dir_path):\n",
    "    \n",
    "    if image_dir_path:\n",
    "    \n",
    "      image_path = []\n",
    "      \n",
    "      for idx, folder in enumerate(os.listdir(image_dir_path)):\n",
    "        Image_dir = os.path.join(image_dir_path, folder)\n",
    "        if os.path.isdir(Image_dir):\n",
    "          for file in os.listdir(Image_dir):\n",
    "            if file.lower().endswith((\"jpg\",\"png\")):\n",
    "              image_full_path = os.path.join(Image_dir, file)\n",
    "              image_path.append((image_full_path, idx))\n",
    "            \n",
    "    return image_path\n",
    "        \n",
    "  def __len__(self):\n",
    "    return len(self.image)\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    \n",
    "    image, label = self.image[index]\n",
    "    try:\n",
    "      image = Image.open(image).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "      return None, None\n",
    "    if image is None:\n",
    "      return None, None\n",
    "    image = self.transform(image)\n",
    "    if torch.isnan(image).any():\n",
    "      print(f\"Nan Detected in image at index {index}\")\n",
    "      return None, None\n",
    "      \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc726d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"DatasetPath\"\n",
    "dataset = SiameseDataset(image_dir= image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414d37c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "  batch = [item for item in batch if item[0] is not None]\n",
    "  if batch is None:\n",
    "    return None\n",
    "  image, label = zip(*batch)\n",
    "  return torch.stack(image), torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb71713",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "generator = torch.Generator()\n",
    "\n",
    "train_data, test_data = random_split(dataset, [train_size, test_size], generator)\n",
    "\n",
    "Train_loader = DataLoader(train_data, batch_size=64, shuffle= True, drop_last= True, collate_fn=collate_fn)\n",
    "Test_loader = DataLoader(test_data, batch_size=64, shuffle=True, drop_last= True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c6a863",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Siamese_network(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Siamese_network, self).__init__()\n",
    "    \n",
    "    base_model = resnet18(weights = ResNet18_Weights.DEFAULT)\n",
    "    \n",
    "    for param in base_model.parameters():\n",
    "      param.requires_grad = False\n",
    "    \n",
    "    self.feature = nn.Sequential(*list(base_model.children())[:-1])\n",
    "    \n",
    "    self.fc = nn.Sequential(\n",
    "      nn.Dropout(0.2, inplace= True),\n",
    "      nn.Linear(512, 128)\n",
    "    )\n",
    "    \n",
    "  def forward(self, x1, x2):\n",
    "    x1 = self.forward_once(x1)\n",
    "    x2 = self.forward_once(x2)\n",
    "    \n",
    "    dist = pairwise_distance(x1, x2)\n",
    "    \n",
    "    return dist\n",
    "    \n",
    "  def forward_once(self, x):\n",
    "    \n",
    "    x = self.feature(x).view(x.size(0), -1)\n",
    "    return f.normalize(self.fc(x), 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132dd209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semi_hard_batching(embedding, label, margin = 0.3):\n",
    "  \n",
    "  batch_size = embedding.size(0)\n",
    "  dist = torch.cdist(embedding, embedding ,p=2)\n",
    "  \n",
    "  anchor, positive, negative = [], [], []\n",
    "  \n",
    "  for i in range(batch_size):\n",
    "    \n",
    "    mask_positive = (label == label[i])\n",
    "    mask_positive[i] = False\n",
    "    mask_negative = (label != label[i])\n",
    "    \n",
    "    if not mask_positive.any() or not mask_negative.any():\n",
    "      continue\n",
    "    \n",
    "    pos_id = torch.where(mask_positive)[0]\n",
    "    neg_id = torch.where(mask_negative)[0]\n",
    "    \n",
    "    d_positive = dist[i, pos_id]\n",
    "    d_negative = dist[i, neg_id]\n",
    "    \n",
    "    mask = (d_negative.unsqueeze(1) > d_positive.unsqueeze(0)) & (d_negative.unsqueeze(1) < d_positive.unsqueeze(0) + margin)\n",
    "    \n",
    "    neg_i, pos_i = torch.nonzero(mask, as_tuple=True)\n",
    "    for ni, pi in zip(neg_i.tolist(), pos_i.tolist()):\n",
    "        anchor.append(i)\n",
    "        positive.append(pos_id[pi].item())\n",
    "        negative.append(neg_id[ni].item())\n",
    "\n",
    "  if not anchor:\n",
    "      empty = torch.empty(0, dtype=torch.long)\n",
    "      return empty, empty, empty\n",
    "\n",
    "  return (\n",
    "      torch.tensor(anchor, dtype=torch.long),\n",
    "      torch.tensor(positive, dtype=torch.long),\n",
    "      torch.tensor(negative, dtype=torch.long),\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54cb9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "Epochs = 50\n",
    "model = Siamese_network().to(device)\n",
    "criterion = TripletMarginLoss(margin= 0.5)\n",
    "optimizer = Adam(model.parameters(), lr = 1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode= 'min', factor= 0.3, patience= 5)\n",
    "earlystop = Earlystopper(min_delta= 0.01, patience= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37d7373",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_stat_A = []\n",
    "acc_stat_B = []\n",
    "\n",
    "loss_stat_A = []\n",
    "loss_stat_B = []\n",
    "\n",
    "for Epoch in range(Epochs):\n",
    "  model.train()\n",
    "  \n",
    "  running_loss = 0\n",
    "  running_acc = 0\n",
    "  \n",
    "  for x_train in tqdm(Train_loader, total= len(Train_loader), desc = f\"Epoch: {Epoch + 1} / {Epochs} - Training:\", leave = False):\n",
    "    \n",
    "    img, label = [data.to(device) for data in x_train]\n",
    "    \n",
    "    embedding = model.forward_once(img)\n",
    "    \n",
    "    a, p, n = semi_hard_batching(embedding, label)\n",
    "    \n",
    "    if a.numel() == 0:\n",
    "      continue\n",
    "    \n",
    "    a = embedding[a]\n",
    "    p = embedding[p]\n",
    "    n = embedding[n]\n",
    "    \n",
    "    dist_A = pairwise_distance(a, p)\n",
    "    dist_B = pairwise_distance(a, n)\n",
    "    \n",
    "    loss = criterion(a, p, n)\n",
    "    acc = Accuracy(a, p, n)\n",
    "    \n",
    "    running_loss += loss.item()\n",
    "    running_acc += acc\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "  Train_loss = running_loss / len(Train_loader)\n",
    "  Train_acc = running_acc / len(Train_loader)\n",
    "  loss_stat_A.append(Train_loss)\n",
    "  acc_stat_A.append(Train_acc)\n",
    "\n",
    "     \n",
    "  model.eval()\n",
    "  with torch.inference_mode():\n",
    "    \n",
    "    test_running_loss = 0\n",
    "    test_running_acc = 0\n",
    "    \n",
    "    for x_test in tqdm(Test_loader, total = len(Test_loader), desc= f\"Epoch: {Epoch + 1} / {Epochs} - Testing\", leave= False):\n",
    "\n",
    "      img, label= [data.to(device) for data in x_test]\n",
    "      embedding = model.forward_once(img)\n",
    "      \n",
    "      a, p, n = semi_hard_batching(embedding, label)\n",
    "      \n",
    "      if a.numel() == 0:\n",
    "        continue\n",
    "      \n",
    "      a = embedding[a]\n",
    "      p = embedding[p]\n",
    "      n = embedding[n]\n",
    "      \n",
    "      test_loss = criterion(a, p ,n)\n",
    "      test_acc = Accuracy(a, p, n)\n",
    "      \n",
    "      test_running_loss += test_loss.item()\n",
    "      test_running_acc += test_acc\n",
    "      \n",
    "  Test_loss = test_running_loss / len(Test_loader)\n",
    "  Test_acc = test_running_acc / len(Test_loader)\n",
    "  loss_stat_B.append(Test_loss)\n",
    "  acc_stat_B.append(test_acc)\n",
    "  \n",
    "  scheduler.step(Test_loss)\n",
    "  \n",
    "  if earlystop.earlystop(Test_loss, model):\n",
    "    earlystop.restore_best_weight(model)\n",
    "    break\n",
    "  \n",
    "  print(f\"Epoch: {Epoch+1}\\t|Train Acc: {Train_acc:.02f}%\\t|Train Loss: {Train_loss:.02f}%\\t|Val Acc: {Test_acc:.02f}%\\t|Val Loss: {Test_loss:.02f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b79b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_distance(result,device):\n",
    "  \n",
    "  plt.figure(figsize= (9, 3))\n",
    "  label = [\"Accuracy\", \"Valid Accuracy\",\"Loss\", \"Valid Loss\"]\n",
    "  \n",
    "  for i in range(4):\n",
    "    \n",
    "    if i < 1:\n",
    "      plt.subplot(2, 2, i + 1)\n",
    "      plt.title(label[i])\n",
    "      plt.plot(result[i])\n",
    "    else:\n",
    "      plt.subplot(2, 2, i + 1)\n",
    "      plt.title(label[i])\n",
    "      plt.plot(result[i])\n",
    "  \n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "  \n",
    "visualize_distance((acc_stat_A, acc_stat_B, loss_stat_A, loss_stat_B), device)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10162554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "\n",
    "  model_path = \"SavePath\"\n",
    "  model_name = \"modelName.pth\"\n",
    "  model_save_path = os.path.join(model_path, model_name)\n",
    "\n",
    "  torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "\n",
    "save_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
